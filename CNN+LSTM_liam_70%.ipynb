{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this discussion, we will build a basic hybrid CNN-LSTM model for classification on the EEG dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook has been created by Tonmoy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (i) Importing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 20:14:45.797233: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten,Dropout\n",
    "from keras.layers import Conv2D,LSTM,BatchNormalization,MaxPooling2D,Reshape\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (ii) Preprocessing the dataset and preparing the training, validation, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(X,y,sub_sample,average,noise):\n",
    "    \n",
    "    total_X = None\n",
    "    total_y = None\n",
    "    \n",
    "    # Trimming the data (sample,22,1000) -> (sample,22,500)\n",
    "    X = X[:,:,0:500]\n",
    "    print('Shape of X after trimming:',X.shape)\n",
    "    \n",
    "    # Maxpooling the data (sample,22,1000) -> (sample,22,500/sub_sample)\n",
    "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n",
    "    \n",
    "    \n",
    "    total_X = X_max\n",
    "    total_y = y\n",
    "    print('Shape of X after maxpooling:',total_X.shape)\n",
    "    \n",
    "    # Averaging + noise \n",
    "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n",
    "    X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
    "    \n",
    "    total_X = np.vstack((total_X, X_average))\n",
    "    total_y = np.hstack((total_y, y))\n",
    "    print('Shape of X after averaging+noise and concatenating:',total_X.shape)\n",
    "    \n",
    "    # Subsampling\n",
    "    \n",
    "    for i in range(sub_sample):\n",
    "        \n",
    "        X_subsample = X[:, :, i::sub_sample] + \\\n",
    "                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
    "            \n",
    "        total_X = np.vstack((total_X, X_subsample))\n",
    "        total_y = np.hstack((total_y, y))\n",
    "        \n",
    "    \n",
    "    print('Shape of X after subsampling and concatenating:',total_X.shape)\n",
    "    return total_X,total_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X after trimming: (1740, 22, 500)\n",
      "Shape of X after maxpooling: (1740, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (3480, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (6960, 22, 250)\n",
      "Shape of X after trimming: (375, 22, 500)\n",
      "Shape of X after maxpooling: (375, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (750, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (1500, 22, 250)\n",
      "Shape of X after trimming: (443, 22, 500)\n",
      "Shape of X after maxpooling: (443, 22, 250)\n",
      "Shape of X after averaging+noise and concatenating: (886, 22, 250)\n",
      "Shape of X after subsampling and concatenating: (1772, 22, 250)\n",
      "Shape of training set: (6960, 22, 250)\n",
      "Shape of validation set: (1500, 22, 250)\n",
      "Shape of training labels: (6960,)\n",
      "Shape of validation labels: (1500,)\n",
      "Shape of testing set: (1772, 22, 250)\n",
      "Shape of testing labels: (1772,)\n",
      "Shape of training labels after categorical conversion: (6960, 4)\n",
      "Shape of validation labels after categorical conversion: (1500, 4)\n",
      "Shape of test labels after categorical conversion: (1772, 4)\n",
      "Shape of training set after adding width info: (6960, 22, 250, 1)\n",
      "Shape of validation set after adding width info: (1500, 22, 250, 1)\n",
      "Shape of test set after adding width info: (1772, 22, 250, 1)\n",
      "Shape of training set after dimension reshaping: (6960, 250, 1, 22)\n",
      "Shape of validation set after dimension reshaping: (1500, 250, 1, 22)\n",
      "Shape of test set after dimension reshaping: (1772, 250, 1, 22)\n"
     ]
    }
   ],
   "source": [
    "## Loading the dataset\n",
    "\n",
    "\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")\n",
    "\n",
    "## Adjusting the labels so that \n",
    "\n",
    "# Cue onset left - 0\n",
    "# Cue onset right - 1\n",
    "# Cue onset foot - 2\n",
    "# Cue onset tongue - 3\n",
    "\n",
    "y_train_valid -= 769\n",
    "y_test -= 769\n",
    "\n",
    "\n",
    "## Random splitting and reshaping the data\n",
    "# First generating the training and validation indices using random splitting\n",
    "\n",
    "ind_valid = np.random.choice(2115, 375, replace=False)\n",
    "ind_train = np.array(list(set(range(2115)).difference(set(ind_valid))))\n",
    "\n",
    "# Creating the training and validation sets using the generated indices\n",
    "(X_train, X_valid) = X_train_valid[ind_train], X_train_valid[ind_valid] \n",
    "(y_train, y_valid) = y_train_valid[ind_train], y_train_valid[ind_valid]\n",
    "\n",
    "\n",
    "## Preprocessing the dataset\n",
    "x_train,y_train = data_prep(X_train,y_train,2,2,True)\n",
    "x_valid,y_valid = data_prep(X_valid,y_valid,2,2,True)\n",
    "X_test_prep,y_test_prep = data_prep(X_test,y_test,2,2,True)\n",
    "\n",
    "\n",
    "print('Shape of training set:',x_train.shape)\n",
    "print('Shape of validation set:',x_valid.shape)\n",
    "print('Shape of training labels:',y_train.shape)\n",
    "print('Shape of validation labels:',y_valid.shape)\n",
    "print('Shape of testing set:',X_test_prep.shape)\n",
    "print('Shape of testing labels:',y_test_prep.shape)\n",
    "\n",
    "\n",
    "# Converting the labels to categorical variables for multiclass classification\n",
    "y_train = to_categorical(y_train, 4)\n",
    "y_valid = to_categorical(y_valid, 4)\n",
    "y_test = to_categorical(y_test_prep, 4)\n",
    "print('Shape of training labels after categorical conversion:',y_train.shape)\n",
    "print('Shape of validation labels after categorical conversion:',y_valid.shape)\n",
    "print('Shape of test labels after categorical conversion:',y_test.shape)\n",
    "\n",
    "# Adding width of the segment to be 1\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
    "x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
    "print('Shape of training set after adding width info:',x_train.shape)\n",
    "print('Shape of validation set after adding width info:',x_valid.shape)\n",
    "print('Shape of test set after adding width info:',x_test.shape)\n",
    "\n",
    "\n",
    "# Reshaping the training and validation dataset\n",
    "x_train = np.swapaxes(x_train, 1,3)\n",
    "x_train = np.swapaxes(x_train, 1,2)\n",
    "x_valid = np.swapaxes(x_valid, 1,3)\n",
    "x_valid = np.swapaxes(x_valid, 1,2)\n",
    "x_test = np.swapaxes(x_test, 1,3)\n",
    "x_test = np.swapaxes(x_test, 1,2)\n",
    "print('Shape of training set after dimension reshaping:',x_train.shape)\n",
    "print('Shape of validation set after dimension reshaping:',x_valid.shape)\n",
    "print('Shape of test set after dimension reshaping:',x_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(443, 1)\n",
      "(2115, 1)\n"
     ]
    }
   ],
   "source": [
    "print(person_test.shape)\n",
    "print(person_train_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (iii)(CNN-LSTM) Defining the architecture of the hybrid CNN-LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_52 (Conv2D)          (None, 250, 1, 25)        2775      \n",
      "                                                                 \n",
      " max_pooling2d_52 (MaxPoolin  (None, 84, 1, 25)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_52 (Bat  (None, 84, 1, 25)        100       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 84, 1, 25)         0         \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 84, 1, 50)         6300      \n",
      "                                                                 \n",
      " max_pooling2d_53 (MaxPoolin  (None, 28, 1, 50)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_53 (Bat  (None, 28, 1, 50)        200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 28, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 28, 1, 100)        25100     \n",
      "                                                                 \n",
      " max_pooling2d_54 (MaxPoolin  (None, 10, 1, 100)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_54 (Bat  (None, 10, 1, 100)       400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 10, 1, 100)        0         \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 10, 1, 200)        100200    \n",
      "                                                                 \n",
      " max_pooling2d_55 (MaxPoolin  (None, 4, 1, 200)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_55 (Bat  (None, 4, 1, 200)        800       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 4, 1, 200)         0         \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 800)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 350)               280350    \n",
      "                                                                 \n",
      " reshape_13 (Reshape)        (None, 350, 1)            0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 35)                5180      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 4)                 144       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421,549\n",
      "Trainable params: 420,799\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the CNN model using sequential class\n",
    "hybrid_cnn_lstm_model = Sequential()\n",
    "\n",
    "# Conv. block 1\n",
    "hybrid_cnn_lstm_model.add(Conv2D(filters=25, kernel_size=(5,1), padding='same', activation='elu', input_shape=(250,1,22)))\n",
    "hybrid_cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same')) # Read the keras documentation\n",
    "hybrid_cnn_lstm_model.add(BatchNormalization())\n",
    "hybrid_cnn_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 2\n",
    "hybrid_cnn_lstm_model.add(Conv2D(filters=50, kernel_size=(5,1), padding='same', activation='elu'))\n",
    "hybrid_cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "hybrid_cnn_lstm_model.add(BatchNormalization())\n",
    "hybrid_cnn_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 3\n",
    "hybrid_cnn_lstm_model.add(Conv2D(filters=100, kernel_size=(5,1), padding='same', activation='elu'))\n",
    "hybrid_cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "hybrid_cnn_lstm_model.add(BatchNormalization())\n",
    "hybrid_cnn_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "# Conv. block 4\n",
    "hybrid_cnn_lstm_model.add(Conv2D(filters=200, kernel_size=(5,1), padding='same', activation='elu'))\n",
    "hybrid_cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "hybrid_cnn_lstm_model.add(BatchNormalization())\n",
    "hybrid_cnn_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "# FC+LSTM layers\n",
    "hybrid_cnn_lstm_model.add(Flatten()) # Adding a flattening operation to the output of CNN block\n",
    "hybrid_cnn_lstm_model.add(Dense((350))) # FC layer with 100 units\n",
    "hybrid_cnn_lstm_model.add(Reshape((350,1))) # Reshape my output of FC layer so that it's compatible\n",
    "hybrid_cnn_lstm_model.add(LSTM(35, dropout=0.6, recurrent_dropout=0.1, input_shape=(350,1), return_sequences=False))\n",
    "\n",
    "# Output layer with Softmax activation \n",
    "hybrid_cnn_lstm_model.add(Dense(4, activation='softmax')) # Output FC layer with softmax activation\n",
    "\n",
    "\n",
    "# Printing the model summary\n",
    "hybrid_cnn_lstm_model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (iv)(CNN-LSTM) Defining the hyperparameters of the hybrid CNN-LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "learning_rate = 1e-3\n",
    "epochs = 50\n",
    "hybrid_cnn_lstm_optimizer = keras.optimizers.Adam(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (v)(CNN-LSTM) Compiling, training and validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "109/109 [==============================] - 46s 393ms/step - loss: 1.3721 - accuracy: 0.2963 - val_loss: 1.3317 - val_accuracy: 0.3293\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 43s 393ms/step - loss: 1.3109 - accuracy: 0.3644 - val_loss: 1.2754 - val_accuracy: 0.4027\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 45s 411ms/step - loss: 1.2260 - accuracy: 0.4326 - val_loss: 1.1838 - val_accuracy: 0.4547\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 42s 384ms/step - loss: 1.1717 - accuracy: 0.4671 - val_loss: 1.1893 - val_accuracy: 0.4740\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 42s 390ms/step - loss: 1.1209 - accuracy: 0.4955 - val_loss: 1.1239 - val_accuracy: 0.5093\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 43s 398ms/step - loss: 1.0869 - accuracy: 0.5161 - val_loss: 1.1370 - val_accuracy: 0.5173\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 42s 384ms/step - loss: 1.0565 - accuracy: 0.5312 - val_loss: 1.1092 - val_accuracy: 0.5053\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 42s 389ms/step - loss: 1.0350 - accuracy: 0.5532 - val_loss: 1.1005 - val_accuracy: 0.5380\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 42s 383ms/step - loss: 1.0084 - accuracy: 0.5711 - val_loss: 1.1413 - val_accuracy: 0.5180\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 43s 396ms/step - loss: 0.9885 - accuracy: 0.5855 - val_loss: 1.0996 - val_accuracy: 0.5453\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 43s 393ms/step - loss: 0.9648 - accuracy: 0.5977 - val_loss: 1.0660 - val_accuracy: 0.5493\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 42s 387ms/step - loss: 0.9218 - accuracy: 0.6213 - val_loss: 1.0511 - val_accuracy: 0.5767\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 43s 393ms/step - loss: 0.9039 - accuracy: 0.6371 - val_loss: 1.0147 - val_accuracy: 0.5913\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 43s 390ms/step - loss: 0.8694 - accuracy: 0.6487 - val_loss: 0.9780 - val_accuracy: 0.6093\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 43s 394ms/step - loss: 0.8615 - accuracy: 0.6510 - val_loss: 1.0073 - val_accuracy: 0.5973\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 43s 392ms/step - loss: 0.8407 - accuracy: 0.6618 - val_loss: 0.9576 - val_accuracy: 0.6340\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 46s 419ms/step - loss: 0.8185 - accuracy: 0.6728 - val_loss: 0.9677 - val_accuracy: 0.6220\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 44s 408ms/step - loss: 0.7929 - accuracy: 0.6889 - val_loss: 0.9174 - val_accuracy: 0.6447\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 42s 384ms/step - loss: 0.7757 - accuracy: 0.6984 - val_loss: 0.9093 - val_accuracy: 0.6333\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 43s 394ms/step - loss: 0.7525 - accuracy: 0.7020 - val_loss: 0.9078 - val_accuracy: 0.6600\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 43s 395ms/step - loss: 0.7336 - accuracy: 0.7155 - val_loss: 0.9438 - val_accuracy: 0.6473\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 42s 382ms/step - loss: 0.7311 - accuracy: 0.7167 - val_loss: 0.9206 - val_accuracy: 0.6627\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 43s 393ms/step - loss: 0.7164 - accuracy: 0.7180 - val_loss: 0.8698 - val_accuracy: 0.6693\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 45s 417ms/step - loss: 0.7050 - accuracy: 0.7296 - val_loss: 0.8651 - val_accuracy: 0.6653\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 44s 401ms/step - loss: 0.6940 - accuracy: 0.7345 - val_loss: 0.9291 - val_accuracy: 0.6367\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 44s 405ms/step - loss: 0.6771 - accuracy: 0.7402 - val_loss: 0.9062 - val_accuracy: 0.6500\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 42s 387ms/step - loss: 0.6821 - accuracy: 0.7379 - val_loss: 0.8686 - val_accuracy: 0.6787\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 43s 393ms/step - loss: 0.6597 - accuracy: 0.7457 - val_loss: 0.8282 - val_accuracy: 0.6907\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 42s 387ms/step - loss: 0.6581 - accuracy: 0.7473 - val_loss: 0.8945 - val_accuracy: 0.6540\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 42s 387ms/step - loss: 0.6394 - accuracy: 0.7534 - val_loss: 0.9210 - val_accuracy: 0.6680\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 43s 394ms/step - loss: 0.6225 - accuracy: 0.7612 - val_loss: 0.8679 - val_accuracy: 0.6887\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 42s 385ms/step - loss: 0.6158 - accuracy: 0.7688 - val_loss: 0.8846 - val_accuracy: 0.6793\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 43s 393ms/step - loss: 0.6095 - accuracy: 0.7716 - val_loss: 0.8918 - val_accuracy: 0.6567\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 43s 394ms/step - loss: 0.6167 - accuracy: 0.7606 - val_loss: 0.8627 - val_accuracy: 0.6767\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 42s 385ms/step - loss: 0.6047 - accuracy: 0.7694 - val_loss: 0.8690 - val_accuracy: 0.6840\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 43s 395ms/step - loss: 0.5862 - accuracy: 0.7759 - val_loss: 0.8628 - val_accuracy: 0.6867\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 43s 392ms/step - loss: 0.5884 - accuracy: 0.7795 - val_loss: 0.9262 - val_accuracy: 0.6540\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 42s 387ms/step - loss: 0.5794 - accuracy: 0.7780 - val_loss: 0.9327 - val_accuracy: 0.6500\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 43s 391ms/step - loss: 0.5607 - accuracy: 0.7876 - val_loss: 0.9473 - val_accuracy: 0.6433\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 42s 382ms/step - loss: 0.5628 - accuracy: 0.7858 - val_loss: 0.8769 - val_accuracy: 0.6647\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 43s 391ms/step - loss: 0.5380 - accuracy: 0.7932 - val_loss: 0.9047 - val_accuracy: 0.6700\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 45s 414ms/step - loss: 0.5358 - accuracy: 0.7967 - val_loss: 0.9217 - val_accuracy: 0.6940\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 43s 392ms/step - loss: 0.5312 - accuracy: 0.7997 - val_loss: 0.8974 - val_accuracy: 0.6633\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 42s 389ms/step - loss: 0.5296 - accuracy: 0.7997 - val_loss: 0.8951 - val_accuracy: 0.6707\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 43s 395ms/step - loss: 0.5342 - accuracy: 0.7945 - val_loss: 0.8437 - val_accuracy: 0.6953\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 43s 393ms/step - loss: 0.5190 - accuracy: 0.8014 - val_loss: 0.8554 - val_accuracy: 0.6887\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 42s 384ms/step - loss: 0.5029 - accuracy: 0.8136 - val_loss: 0.8612 - val_accuracy: 0.6973\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 43s 398ms/step - loss: 0.5003 - accuracy: 0.8108 - val_loss: 0.8418 - val_accuracy: 0.6867\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 57s 527ms/step - loss: 0.4965 - accuracy: 0.8114 - val_loss: 0.8450 - val_accuracy: 0.6973\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 49s 450ms/step - loss: 0.4865 - accuracy: 0.8170 - val_loss: 0.8729 - val_accuracy: 0.6753\n"
     ]
    }
   ],
   "source": [
    "# Compiling the model\n",
    "hybrid_cnn_lstm_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=hybrid_cnn_lstm_optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Training and validating the model\n",
    "hybrid_cnn_lstm_model_results = hybrid_cnn_lstm_model.fit(x_train,\n",
    "             y_train,\n",
    "             batch_size=64,\n",
    "             epochs=epochs,\n",
    "             validation_data=(x_valid, y_valid), verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (vi)(CNN-LSTM) Visualizing the accuracy and loss trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hybrid_cnn_lstm_model_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Plotting accuracy trajectory\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m plt\u001b[39m.\u001b[39mplot(hybrid_cnn_lstm_model_results\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m plt\u001b[39m.\u001b[39mplot(hybrid_cnn_lstm_model_results\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mHybrid CNN-LSTM model accuracy trajectory\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hybrid_cnn_lstm_model_results' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting accuracy trajectory\n",
    "plt.plot(hybrid_cnn_lstm_model_results.history['accuracy'])\n",
    "plt.plot(hybrid_cnn_lstm_model_results.history['val_accuracy'])\n",
    "plt.title('Hybrid CNN-LSTM model accuracy trajectory')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plotting loss trajectory\n",
    "plt.plot(hybrid_cnn_lstm_model_results.history['loss'],'o')\n",
    "plt.plot(hybrid_cnn_lstm_model_results.history['val_loss'],'o')\n",
    "plt.title('Hybrid CNN-LSTM model loss trajectory')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (vii)(CNN-LSTM) Testing the performance of the hybrid CNN-LSTM model on the held out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the hybrid CNN-LSTM model: 0.70033860206604\n"
     ]
    }
   ],
   "source": [
    "## Testing the hybrid CNN-LSTM model\n",
    "\n",
    "hybrid_cnn_lstm_score = hybrid_cnn_lstm_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy of the hybrid CNN-LSTM model:',hybrid_cnn_lstm_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(443, 1)\n",
      "----------\n",
      "(50, 22, 1000)\n",
      "(50, 22, 1000)\n",
      "(50, 22, 1000)\n",
      "(50, 22, 1000)\n",
      "(47, 22, 1000)\n",
      "(49, 22, 1000)\n",
      "(50, 22, 1000)\n",
      "(50, 22, 1000)\n",
      "(47, 22, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(person_test.shape)\n",
    "print(\"----------\")\n",
    "\n",
    "for i in range(9):\n",
    "    person_test_single_idx = list(np.where(person_test == i)[0])\n",
    "    person_test_single = X_test[person_test_single_idx]\n",
    "    print(person_test_single.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2115, 1)\n",
      "(237, 22, 1000)\n",
      "(236, 22, 1000)\n",
      "(236, 22, 1000)\n",
      "(234, 22, 1000)\n",
      "(235, 22, 1000)\n",
      "(236, 22, 1000)\n",
      "(238, 22, 1000)\n",
      "(232, 22, 1000)\n",
      "(231, 22, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(person_train_valid.shape)\n",
    "\n",
    "for i in range(9):\n",
    "    person_train_valid_single_idx = list(np.where(person_train_valid == i)[0])\n",
    "    person_train_valid_single = X_train_valid[person_train_valid_single_idx]\n",
    "    print(person_train_valid_single.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
